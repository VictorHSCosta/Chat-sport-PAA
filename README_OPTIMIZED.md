# ğŸš€ Chat Sport RAG - Ultra Performance Edition

Sistema de chat especializado em futebol usando **RAG (Retrieval-Augmented Generation)** com otimizaÃ§Ãµes extremas de performance.

## âš¡ Performance Otimizada

- **Respostas em cache**: < 0.5 segundos âš¡
- **Perguntas sobre PelÃ©, Messi, Copa**: < 0.5 segundos âš¡  
- **Outras perguntas**: 3-30 segundos ğŸš€
- **Timeout mÃ¡ximo**: 150 segundos para respostas completas

## ğŸ—ï¸ Arquitetura

### Backend (FastAPI + RAG)
- **LLM**: Ollama (tinyllama) ultra-otimizado
- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2 (rÃ¡pido)
- **Vector Store**: FAISS com chunks de 200 caracteres
- **Cache inteligente**: Respostas instantÃ¢neas para perguntas frequentes
- **Timeout estendido**: 120s backend + 150s frontend para respostas completas

### Frontend (React + Vite)
- Interface de chat moderna e responsiva
- Indicador de status da API em tempo real
- Timeout estendido no cliente (150 segundos)
- SugestÃµes de perguntas interativas

## ğŸš€ InstalaÃ§Ã£o RÃ¡pida

### 1. ConfiguraÃ§Ã£o Inicial
```bash
# Clone o repositÃ³rio
git clone <repo-url>
cd Chat-sport-PAA

# Execute a configuraÃ§Ã£o automÃ¡tica
chmod +x setup.sh
./setup.sh
```

### 2. Iniciar Ollama (obrigatÃ³rio)
```bash
# Em um terminal separado
ollama serve

# O setup.sh jÃ¡ baixa o modelo, mas se precisar:
ollama pull tinyllama
```

### 3. Iniciar o Projeto
```bash
# Iniciar tudo (backend + frontend)
./start.sh

# Ou separadamente:
./start.sh backend   # SÃ³ backend
./start.sh frontend  # SÃ³ frontend
```

## ğŸ¯ URLs Importantes

- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **Docs da API**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

## ğŸ”§ Scripts DisponÃ­veis

```bash
./start.sh              # Inicia tudo
./start.sh backend      # SÃ³ backend
./start.sh frontend     # SÃ³ frontend  
./start.sh test         # Testa performance
./start.sh optimize     # Recriar Ã­ndice FAISS
```

## âš¡ OtimizaÃ§Ãµes Implementadas

### Cache Inteligente
Respostas instantÃ¢neas para:
- "PelÃ©" / "histÃ³ria do PelÃ©"
- "Messi" 
- "Copa do Mundo"
- "Brasil"
- E muito mais...

### LLM Otimizado para Respostas Completas
- Temperatura: 0.2 (respostas consistentes)
- MÃ¡ximo: 300 tokens (respostas completas)
- Stop words melhorados para evitar cortes
- Timeout: 120 segundos para processamento completo
- LLM timeout: 60 segundos por chamada

### Retrieval Otimizado
- Chunks: 300 caracteres (vs 1000 antes)
- SobreposiÃ§Ã£o: 20 caracteres
- Busca: apenas 1 documento mais relevante
- Embedding rÃ¡pido: all-MiniLM-L6-v2

## ğŸ§ª Testando Performance

```bash
# Teste automatizado de performance
./start.sh test

# Teste manual via curl
curl -X POST "http://localhost:8000/chat" \
     -H "Content-Type: application/json" \
     -d '{"message": "Qual a histÃ³ria do PelÃ©?"}' \
     -w "\nTempo: %{time_total}s\n"
```

## ğŸ“Š Estrutura do Projeto

```
Chat-sport-PAA/
â”œâ”€â”€ backend/                 # API FastAPI
â”‚   â”œâ”€â”€ api.py              # API principal otimizada
â”‚   â”œâ”€â”€ optimize_index.py   # Script de otimizaÃ§Ã£o FAISS
â”‚   â”œâ”€â”€ test_performance.sh # Testes de performance
â”‚   â”œâ”€â”€ requirements.txt    # DependÃªncias Python
â”‚   â”œâ”€â”€ data.txt           # Base de conhecimento
â”‚   â””â”€â”€ faiss_index_/      # Ãndice vetorial otimizado
â”œâ”€â”€ Front/front-end/        # Interface React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # Componentes React
â”‚   â”‚   â”œâ”€â”€ hooks/         # Hooks customizados
â”‚   â”‚   â””â”€â”€ services/      # API cliente
â”‚   â””â”€â”€ package.json       # DependÃªncias Node.js
â”œâ”€â”€ start.sh               # Script principal (NOVO!)
â”œâ”€â”€ setup.sh              # ConfiguraÃ§Ã£o inicial (NOVO!)
â””â”€â”€ README.md             # Este arquivo
```

## ğŸ® Como Usar

1. **Perguntas rÃ¡pidas** (cache instantÃ¢neo):
   - "Qual a histÃ³ria do PelÃ©?"
   - "Quem Ã© Messi?"
   - "Quantas Copas o Brasil tem?"

2. **Perguntas complexas** (RAG em 1-3s):
   - "Compare PelÃ© e Messi"
   - "HistÃ³ria da Copa do Mundo de 1970"
   - "Maiores artilheiros da Champions"

3. **Interface**:
   - Digite sua pergunta
   - Clique nas sugestÃµes
   - Veja o status da API (ğŸŸ¢ Online / ğŸ”´ Offline)

## ğŸ› Troubleshooting

### Backend nÃ£o inicia
```bash
# Verificar se Ollama estÃ¡ rodando
pgrep ollama

# Se nÃ£o estiver:
ollama serve

# Recriar ambiente virtual
rm -rf backend/footbot
./setup.sh
```

### Frontend com erro
```bash
cd Front/front-end
rm -rf node_modules
pnpm install
```

### Performance baixa
```bash
# Recriar Ã­ndice otimizado
./start.sh optimize

# Testar performance
./start.sh test
```

### Timeout frequente
1. Verificar se Ollama estÃ¡ saudÃ¡vel: `ollama list`
2. Usar perguntas mais simples
3. Verificar cache: perguntas sobre PelÃ© devem ser instantÃ¢neas

## ğŸ” Debug e AnÃ¡lise

### Endpoint de Debug
Para anÃ¡lise detalhada das respostas:
```bash
curl -X POST "http://localhost:8000/chat-debug" \
     -H "Content-Type: application/json" \
     -d '{"message": "fale sobre messi"}' | jq '.'
```

### Monitoramento em Tempo Real
- **Logs do backend**: Mostram processo completo de geraÃ§Ã£o
- **Status da API**: http://localhost:8000/status
- **Teste de respostas completas**: `./backend/test_complete_responses.sh`

### Verificando Respostas Incompletas
Se as respostas estÃ£o sendo cortadas:
1. Use `/chat-debug` para anÃ¡lise detalhada
2. Verifique logs do backend para tokens gerados
3. Aumente `num_predict` se necessÃ¡rio
4. Verifique se o modelo Ollama estÃ¡ saudÃ¡vel

## ğŸ¤ Contribuindo

1. FaÃ§a um fork
2. Crie uma branch: `git checkout -b feature/nova-feature`
3. Commit: `git commit -m 'Adiciona nova feature'`
4. Push: `git push origin feature/nova-feature`
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

MIT License - veja o arquivo LICENSE para detalhes.

---

**âš¡ VersÃ£o Ultra-Performance** - Respostas em segundos, nÃ£o minutos!
